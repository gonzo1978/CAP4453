{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3. image_filtering.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gonzo1978/CAP4453/blob/main/3_image_filtering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKN_7d1fuHQq"
      },
      "source": [
        "#Homework 3\n",
        "1. Upload a personal image in hosting place that can be accesed using an URL.\n",
        "2. Perform filtering using a 3x3 and then a 5x5 box filter. Show the resulting images. What is the effect of applying a box filter. Explain the differences between the two resulting images.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhiuE4svvKmf"
      },
      "source": [
        "from skimage import io\n",
        "import cv2\n",
        "\n",
        "#yourUrl = 'http://..'\n",
        "image = io.imread(yourUrl)\n",
        "\n",
        "# convert to BGR if you are using openCV\n",
        "image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
        "\n",
        "#prepare the 3x3 shaped filter\n",
        "#k1 = np.array([[],[],[]])\n",
        "\n",
        "#prepare the 5x5 shaped filter\n",
        "#k2 = np.array([[],[],[],[],[]])\n",
        "\n",
        "# Normalize the kernels if needed. 3x3 filter has 1/9 factor, 5x5 has a 1/25 factor\n",
        "\n",
        "\n",
        "# apply filter\n",
        "#final_frame = cv2.filter2D()\n",
        "\n",
        "#make sure you are the right data type and values. You can use histogram to check it\n",
        "# 0-255 if uint8\n",
        "# 0-1 if float\n",
        "\n",
        "# visualize\n",
        "#cv2_imshow(final_frame)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Et0nokFQwfke"
      },
      "source": [
        "3. Obtain and print two-dimensional Gaussian kernels with the following characteristics:<br>\n",
        "a) $\\sigma^2 = 1$, kernel size: 3x3, <br>b) $\\sigma^2 = 1.2$, kernel size: 5x5, <br> c) $\\sigma^2 = 1.6$, kernel size: 9x9.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcCEKEm6yKgB"
      },
      "source": [
        "#add your code here\n",
        "\n",
        "# A possible implementation is here. Modify it play with it:\n",
        "#\n",
        "#import numpy as np\n",
        "\n",
        "#def gkern(l=5, sig=1.):\n",
        "#    \"\"\"\\\n",
        "#    creates gaussian kernel with side length l and a sigma of sig\n",
        "#    \"\"\"\n",
        "#    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)\n",
        "#    xx, yy = np.meshgrid(ax, ax)\n",
        "#    kernel = np.exp(-0.5 * (np.square(xx) + np.square(yy)) / np.square(sig))\n",
        "#    return kernel / np.sum(kernel)   #note that this normalize the filter to 1. is it desirable?.\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "liyCUA83sxDd"
      },
      "source": [
        "4. Apply the three\n",
        "Gaussian kernels obtained previously on your uploaded image. show your filter results. Discuss the differences of\n",
        "Gaussian operations with different sigmas. Also, compare your results with question 2: what are the differences between these ﬁlters, what do you observe ? Which ﬁltering is the most eﬀective in which images ? Why ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQsiu4yu0AfW"
      },
      "source": [
        "Add your comments here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJhMl4xDyJIZ"
      },
      "source": [
        "\n",
        "5. Implement the three steps of Sobel filtering. Apply it to the uploaded image for 3 different thresholds. Show the results on\n",
        "the screen, and discuss the resulting images.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WG8yyZZMx9rs"
      },
      "source": [
        "# step 1. Get x and y gradients . Use the correct kernels\n",
        "#cv2.filter2D()\n",
        "\n",
        "# step 2. Compute the magnitude of the gradient\n",
        "\n",
        "# Step 3. Threshold. Choose 3 different threshold. visualize outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llNQVFNs0QWI"
      },
      "source": [
        "Edit your comments here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqKooHcLyRrT"
      },
      "source": [
        "\n",
        "6. Use canny edge detector incorporated in opencv. Pick two diferent sets of hysteresys thresholds. What can you tell about the effect on the obtained edges.  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehpOIRaQyZ8c"
      },
      "source": [
        "# use the canny from openCV\n",
        "# cv.Canny(\timage, threshold1, threshold2[, edges[, apertureSize[, L2gradient]]]\t)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ac8kqi3A0UfR"
      },
      "source": [
        "Edit your comments here"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, you are going to use morphological operations to try to count automatically the number of rice grains from an image.\n",
        "\n",
        "7. Read image, convert it to gray scale and apply a bilateral filter.\n",
        "<br>A bilateral filter is a filter that smooth where there is not changes on the gray scale preserving values close to edges. To understand bilateral filters  [Click here](https://machinelearningknowledge.ai/bilateral-filtering-in-python-opencv-with-cv2-bilateralfilter/)\n"
      ],
      "metadata": {
        "id": "et96X6Yf4SkQ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxZ58Un10Dcv"
      },
      "source": [
        "from skimage import io\n",
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "image = io.imread('https://i.stack.imgur.com/pgWt1.jpg')   #io.imread reads in the format RGB. if we were using opencv native read, the read with  be already BGR and the following conversion wouldn't be neccesary\n",
        "img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# utilize cvtColor to convert to gray\n",
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# display the gray scale image\n",
        "cv2_imshow(gray)\n",
        "\n",
        "# apply a bilateral filter. Adjust the value to your convenience\n",
        "diameter_neighborhood= 11\n",
        "sigma_color_space = 17\n",
        "sigma_spatial_space = 5\n",
        "gray = cv2.bilateralFilter(gray, diameter_neighborhood, sigma_color_space, sigma_spatial_space)\n",
        "cv2_imshow(gray)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Compute the edges of the previous image with a Canny filter. Adjust the thresholds of the canny filter to obtain the best edge you can."
      ],
      "metadata": {
        "id": "cQIw_WEY_ixF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# use the canny from openCV\n",
        "# threshold1 =\n",
        "# threshold2 =\n",
        "#edges = cv2.Canny(\tgray, threshold1, threshold2)\n",
        "cv2_imshow(edges)\n"
      ],
      "metadata": {
        "id": "pyyehaVf_5Qe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Apply a closing operation to the edges of the image. Experiment with different kernel sizes (3,5,9).\n"
      ],
      "metadata": {
        "id": "g2eyfH1dAkS-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
        "closed = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, kernel)\n",
        "cv2_imshow(closed)"
      ],
      "metadata": {
        "id": "URXpd7pkBRO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. Find the countours (curve joining all the continuous points (along the boundary)) of the object, display the grains you found in the image. Explanation of contours is [here](https://docs.opencv.org/3.4/d4/d73/tutorial_py_contours_begin.html).\n",
        "<br>a) what the values of the variable (array) cnts represents?  <br>b) What the variable \"peri\" represents?  <br>c) Change the color of the contour to red"
      ],
      "metadata": {
        "id": "G2VnLnxMBm8t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "i=0\n",
        "cnts,heir= cv2.findContours(closed.copy(),cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)[-2:]\n",
        "\n",
        "\n",
        "print(\"A total of \" + str(len(cnts)) + \" grains were found\")\n",
        "for c in cnts:\n",
        "\tperi = cv2.arcLength(c, True)\n",
        "\n",
        "  #an approximation of the contour of the figure\n",
        "\tapprox = cv2.approxPolyDP(c, 0.02 * peri, True)\n",
        "\n",
        "\t# Understand what are the parameters of this function\n",
        "\tcv2.drawContours(img, [approx], -1, (0, 255, 0), 2)\n",
        "\n",
        "  # crop the image\n",
        "\tx,y,w,h =cv2.boundingRect(c)\n",
        "\ti=i+1;\n",
        "\tprint(i)\n",
        "\tnewImage=img[y:y+h,x:x+w]\n",
        "\tcv2_imshow(newImage)\n",
        "\n",
        "print(\"the grains\")\n",
        "cv2_imshow(img)\n"
      ],
      "metadata": {
        "id": "7zJTv9gxBZsj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}